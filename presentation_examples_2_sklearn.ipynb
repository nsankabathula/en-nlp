{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import autocorrect\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    'He playeed football',\n",
    "    'He plays cricket',\n",
    "    'He had sandwich for dinner'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cricket</th>\n",
       "      <th>dinner</th>\n",
       "      <th>football</th>\n",
       "      <th>for</th>\n",
       "      <th>had</th>\n",
       "      <th>he</th>\n",
       "      <th>playeed</th>\n",
       "      <th>plays</th>\n",
       "      <th>sandwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>He playeed football</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He plays cricket</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He had sandwich for dinner</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cricket  dinner  football  for  had  he  playeed  \\\n",
       "He playeed football               0       0         1    0    0   1        1   \n",
       "He plays cricket                  1       0         0    0    0   1        0   \n",
       "He had sandwich for dinner        0       1         0    1    1   1        0   \n",
       "\n",
       "                            plays  sandwich  \n",
       "He playeed football             0         0  \n",
       "He plays cricket                1         0  \n",
       "He had sandwich for dinner      0         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Summary (vectorizer, docs):\n",
    "    denseVector = vectorizer.fit_transform(docs).todense()\n",
    "    words = vectorizer.get_feature_names()\n",
    "    summary = pd.DataFrame(denseVector,columns = words, index = docs)\n",
    "    return summary\n",
    "    \n",
    "cv = CountVectorizer(lowercase = True)\n",
    "DTM = cv.fit_transform(docs).todense()\n",
    "words = cv.get_feature_names()\n",
    "summary = pd.DataFrame(DTM,columns = words, index = docs)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def process(doc):\n",
    "    s_doc = nlp(doc)\n",
    "    tokens = []\n",
    "    for token in s_doc:\n",
    "        #print(token, token.lemma_, token.pos_)\n",
    "        if(token.lemma_ == 'PRON' or token.lemma_ == '-PRON-'):\n",
    "            tokens.append(token.lower_)\n",
    "        else:\n",
    "            tokens.append(token.lemma_)    \n",
    "    #print (tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "class SpellTokenizer(object):\n",
    "    \n",
    "    def __init__(self, nlp):\n",
    "        self.vocab = nlp.vocab\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        doc = nlp.tokenizer(text)\n",
    "        words = [autocorrect.spell(i.orth_) for i in doc]\n",
    "        return spacy.tokens.Doc(self.vocab, words = words)\n",
    "\n",
    "nlp.make_doc = SpellTokenizer(nlp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cricket</th>\n",
       "      <th>dinner</th>\n",
       "      <th>football</th>\n",
       "      <th>for</th>\n",
       "      <th>have</th>\n",
       "      <th>he</th>\n",
       "      <th>play</th>\n",
       "      <th>sandwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>He playeed football</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He plays cricket</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He had sandwich for dinner</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cricket  dinner  football  for  have  he  play  \\\n",
       "He playeed football               0       0         1    0     0   1     1   \n",
       "He plays cricket                  1       0         0    0     0   1     1   \n",
       "He had sandwich for dinner        0       1         0    1     1   1     0   \n",
       "\n",
       "                            sandwich  \n",
       "He playeed football                0  \n",
       "He plays cricket                   0  \n",
       "He had sandwich for dinner         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(preprocessor = process)\n",
    "Summary(cv, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/en-nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cricket</th>\n",
       "      <th>dinner</th>\n",
       "      <th>football</th>\n",
       "      <th>for</th>\n",
       "      <th>have</th>\n",
       "      <th>he</th>\n",
       "      <th>play</th>\n",
       "      <th>sandwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>He playeed football</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He plays cricket</th>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He had sandwich for dinner</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479528</td>\n",
       "      <td>0.479528</td>\n",
       "      <td>0.283217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             cricket    dinner  football       for      have  \\\n",
       "He playeed football         0.000000  0.000000  0.720333  0.000000  0.000000   \n",
       "He plays cricket            0.720333  0.000000  0.000000  0.000000  0.000000   \n",
       "He had sandwich for dinner  0.000000  0.479528  0.000000  0.479528  0.479528   \n",
       "\n",
       "                                  he      play  sandwich  \n",
       "He playeed football         0.425441  0.547832  0.000000  \n",
       "He plays cricket            0.425441  0.547832  0.000000  \n",
       "He had sandwich for dinner  0.283217  0.000000  0.479528  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary(TfidfVectorizer(preprocessor = process), docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequencyâ€“Inverse Document Frequency (TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = [\n",
    "    'He playeed football',\n",
    "    'He plays cricket',\n",
    "    'He had sandwich for dinner',\n",
    "    'Sandwich i had for lunch was great',\n",
    "    \"He is neither a friend nor is he a foe\",    \n",
    "    \n",
    "]\n",
    "#Summary(CountVectorizer(preprocessor = process, ngram_range=(1, 3)), docs)\n",
    "\n",
    "#cv = CountVectorizer(preprocessor = process)\n",
    "#DTM = cv.fit_transform(docs).todense()\n",
    "#words = cv.get_feature_names()\n",
    "#summary = pd.DataFrame(DTM,columns = words, index = docs)\n",
    "#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary(TfidfVectorizer(preprocessor = process, ngram_range=(1, 3)), docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('He had sandwich for dinner', 2)\n",
      "('He is neither a friend nor is he a foe', 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/en-nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "def getSimilarDocsCV(query, docs):\n",
    "    \n",
    "    vectorizer = CountVectorizer(preprocessor = process, ngram_range=(1, 2)) #CountVectorizer\n",
    "    dtm = vectorizer.fit_transform(docs).todense()\n",
    "    \n",
    "    query_vector = getVector(query, vectorizer)\n",
    "    similarities = computeSimilarities(query_vector, dtm)\n",
    "    mostSimilarDocIdx = getMostSimilarIdx(similarities)\n",
    "    return docs[mostSimilarDocIdx], mostSimilarDocIdx;\n",
    "\n",
    "def getSimilarDocsTfidf(query, docs):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(preprocessor = process, ngram_range=(1, 2)) #TfidfVectorizer\n",
    "    dtm = vectorizer.fit_transform(docs).todense()\n",
    "    \n",
    "    query_vector = getVector(query, vectorizer)\n",
    "    similarities = computeSimilarities(query_vector, dtm)\n",
    "    mostSimilarDocIdx = getMostSimilarIdx(similarities)\n",
    "    return docs[mostSimilarDocIdx], mostSimilarDocIdx;\n",
    "\n",
    "def getVector(query, vectorizer):\n",
    "    query_vector = vectorizer.transform([query]).todense()\n",
    "    return query_vector\n",
    "\n",
    "def computeSimilarities(query_vector, dtm):\n",
    "    all_vectors = np.concatenate((dtm, query_vector))\n",
    "    similarities = cosine_similarity(all_vectors)[-1][:-1]\n",
    "    return similarities\n",
    "\n",
    "def getMostSimilarIdx(similarities):\n",
    "    return np.argmax(similarities)\n",
    "\n",
    "def getLeastSimilarIdx(similarities):\n",
    "    return np.argmin(similarities)\n",
    "\n",
    "print(getSimilarDocsTfidf(\"dinner was awesome\", docs))\n",
    "print(getSimilarDocsCV(\"dinner was awesome\", docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    'Welcome to the weekly book review, my favorite' ,\n",
    "    'This isnt news, but the president discussed his favorite book',\n",
    "    'In the news today the president said',\n",
    "    'Obama stands by EPA about pollution',\n",
    "    'Obama against Wall street'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarDocsWordVector(query, docs):\n",
    "    dtm = list(map(lambda doc: nlp(doc).vector,  docs) )         # Word Vectors\n",
    "    query_vector = nlp(query).vector\n",
    "    all_vectors = dtm + [query_vector]\n",
    "    similarities = cosine_similarity(all_vectors)[-1][:-1]\n",
    "    mostSimilarDocIdx = getMostSimilarIdx(similarities)\n",
    "    return docs[mostSimilarDocIdx], mostSimilarDocIdx;\n",
    "\n",
    "#getSimilarDocsWordVector(\"President coal\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFDIF Vector:  ('In the news today the president said', 2)\n",
      "Count Vector:  ('In the news today the president said', 2)\n",
      "Word Vector:  ('Obama stands by EPA about pollution', 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/en-nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "print(\"TFDIF Vector: \", getSimilarDocsTfidf(\"President coal\", docs))\n",
    "print(\"Count Vector: \", getSimilarDocsCV(\"President coal\", docs))\n",
    "print(\"Word Vector: \", getSimilarDocsWordVector(\"President coal\", docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"President\").vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.94145131e+00,  1.30941749e+00,  5.03938103e+00,  2.40374613e+00,\n",
       "       -1.32454109e+00,  4.81367064e+00, -3.52691984e+00, -2.37943292e+00,\n",
       "        1.00874412e+00, -8.12833607e-02, -6.13715649e-01,  1.07234538e+00,\n",
       "       -5.55517972e-02, -2.64275670e+00,  4.40189362e-01,  2.88332200e+00,\n",
       "        4.80573475e-01, -3.61144185e+00, -1.87545180e+00, -8.40450287e-01,\n",
       "       -1.44577527e+00,  8.83387804e-01, -2.09199727e-01, -7.49470472e-01,\n",
       "       -3.38787842e+00, -6.93196595e-01, -1.42271012e-01,  5.82755804e-01,\n",
       "       -3.62339759e+00, -2.46968341e+00, -9.55463350e-01, -2.34903288e+00,\n",
       "        2.64658833e+00, -1.75681674e+00,  3.16621542e-01, -1.17007875e+00,\n",
       "       -1.64229321e+00,  1.12336838e+00, -3.52560341e-01,  8.93644214e-01,\n",
       "       -1.95932913e+00,  3.50284338e+00,  1.79270291e+00, -1.82425094e+00,\n",
       "       -3.59568787e+00,  2.62061596e+00, -7.66131222e-01,  7.05506206e-01,\n",
       "        2.88515615e+00, -4.78165269e-01, -1.67668509e+00, -1.52667725e+00,\n",
       "       -2.33446097e+00, -1.40634477e+00,  8.10547590e-01, -9.66774940e-01,\n",
       "       -9.18616891e-01,  1.57271647e+00, -1.08077407e+00, -1.20850575e+00,\n",
       "       -8.02123368e-01,  1.09764004e+00, -1.65044069e+00,  3.88844013e+00,\n",
       "        1.50592816e+00, -2.52753496e+00,  3.63504839e+00, -6.70065880e-01,\n",
       "       -1.57309377e+00,  2.05017376e+00,  1.89620566e+00, -3.16983986e+00,\n",
       "        1.78342366e+00,  4.40064526e+00, -2.20749807e+00, -5.28093815e-01,\n",
       "        1.94173825e+00, -2.94090557e+00,  5.07993102e-01,  1.11207438e+00,\n",
       "       -2.80483890e+00, -4.99211758e-01, -2.41891336e+00, -2.59327650e+00,\n",
       "        6.86520338e-01,  2.57646799e+00, -2.60664463e+00,  2.04228729e-01,\n",
       "        9.76046324e-01,  1.66093910e+00, -9.47610021e-01,  5.60138178e+00,\n",
       "       -5.26084125e-01,  1.52276218e+00,  2.58384109e-01,  5.52094817e-01,\n",
       "       -2.39704823e+00,  1.69976383e-01,  3.30748725e+00, -1.08899426e+00,\n",
       "       -2.10462308e+00,  4.01533747e+00,  1.63441610e+00, -3.26453090e-01,\n",
       "       -3.76988083e-01,  1.55190557e-01,  3.73788023e+00, -2.37649083e+00,\n",
       "        1.06059694e+00,  2.13179898e+00, -4.37388420e-01, -1.07966447e+00,\n",
       "        1.37068462e+00, -4.43651819e+00,  1.64790022e+00,  8.57891977e-01,\n",
       "       -8.57457221e-02,  5.60413504e+00, -2.46961308e+00,  7.86626101e-01,\n",
       "        1.13344407e+00,  2.54521656e+00,  3.90166521e+00,  2.43782568e+00,\n",
       "       -9.34867859e-02, -3.68778896e+00,  3.18382788e+00,  9.49415088e-01,\n",
       "       -1.46410614e-01, -3.33857089e-01,  4.01609480e-01, -6.51276261e-02,\n",
       "       -5.42482078e-01, -1.62285253e-01, -9.03311133e-01,  8.76759171e-01,\n",
       "        1.94157690e-01,  3.09275985e-01,  3.95549595e-01, -1.69864535e-01,\n",
       "        1.50813788e-01, -2.11550742e-02,  2.10857511e-01,  2.52829641e-02,\n",
       "       -3.55572701e-01,  7.60950446e-01,  5.26526570e-01, -4.97308820e-01,\n",
       "        1.74600765e-01,  3.30373317e-01,  1.25062466e-01,  2.00286508e-04,\n",
       "       -7.38567561e-02, -5.88480949e-01,  5.55888414e-01, -4.27971005e-01,\n",
       "       -2.35253572e-02, -5.67839861e-01, -5.52883625e-01,  2.66564161e-01,\n",
       "       -3.91704410e-01, -3.33196551e-01, -9.08635259e-02, -3.86650503e-01,\n",
       "        4.89958704e-01,  7.24956989e-01,  4.84573364e-01,  2.35284373e-01,\n",
       "       -2.21444145e-01,  3.66379172e-01, -1.66971087e-01,  4.41366881e-01,\n",
       "       -2.58394599e-01, -3.47060710e-03,  2.16854736e-02, -2.08386496e-01,\n",
       "       -5.87501824e-01,  3.06639493e-01, -5.01468778e-01, -4.51178908e-01,\n",
       "       -4.51311469e-02, -3.36457670e-01,  3.33663195e-01,  4.39175963e-02,\n",
       "        4.43151832e-01, -4.06150490e-01,  1.05872285e+00,  1.05045103e-01,\n",
       "        2.12472439e-01,  1.34863511e-01,  6.94824696e-01, -6.77681863e-02,\n",
       "        6.66565448e-02,  3.98809850e-01, -2.20262423e-01,  6.59697533e-01,\n",
       "        8.50413367e-02, -3.62125784e-02, -5.22218168e-01, -3.03854972e-01,\n",
       "        3.66189241e-01, -1.07269526e-01, -1.55415148e-01,  2.19979286e-01,\n",
       "        6.38895929e-01,  8.72580111e-01, -1.40995130e-01,  4.54891138e-02,\n",
       "        6.32166803e-01, -7.42585063e-01, -1.03821576e+00, -3.66676271e-01,\n",
       "        4.48023558e-01,  2.86019385e-01, -1.31691372e+00, -5.07284760e-01,\n",
       "       -5.17144918e-01, -1.39770806e-01,  2.84659058e-01, -4.01302159e-01,\n",
       "        4.74424660e-02,  2.08847940e-01, -4.16010618e-02, -2.11486712e-01,\n",
       "       -2.49295801e-01, -5.64795017e-01, -2.48823613e-01, -3.65327656e-01,\n",
       "        6.90445676e-02,  7.19113231e-01, -7.95511603e-01,  7.81563759e-01,\n",
       "        9.12803769e-01,  1.91658139e-01, -5.22501349e-01,  5.17182589e-01,\n",
       "       -6.22124135e-01, -3.06914151e-01,  4.38846201e-02, -5.89050055e-01,\n",
       "        4.34221774e-01, -4.31987345e-01,  1.88576758e-01, -2.30944276e-01,\n",
       "       -4.12463903e-01, -1.05814710e-02, -4.49807346e-01,  4.89128470e-01,\n",
       "       -4.35891569e-01, -4.01478201e-01, -4.33369637e-01,  5.90953708e-01,\n",
       "       -2.08882928e-01,  4.64502871e-01,  5.71458340e-01,  4.35012847e-01,\n",
       "       -3.14462245e-01, -3.91884118e-01,  4.30428743e-01, -2.62969255e-01,\n",
       "        1.40166804e-02, -5.64107597e-01,  5.26997983e-01,  2.51974523e-01,\n",
       "       -3.51402760e-01,  2.38497749e-01,  4.75840420e-01,  2.18381166e-01,\n",
       "       -5.81544399e-01, -3.61430049e-01,  1.47137314e-01,  4.49278802e-01,\n",
       "        4.39070910e-02,  2.92092860e-01, -4.17111844e-01, -4.43197161e-01,\n",
       "       -5.71460426e-01, -4.94095117e-01,  7.12114871e-01, -5.11940181e-01,\n",
       "        7.74705410e-02,  5.11259675e-01, -1.08851182e+00,  7.21138000e-01,\n",
       "       -1.03021830e-01,  4.72702831e-01,  1.65191144e-01, -2.91706175e-01,\n",
       "       -4.98581588e-01,  1.18835345e-01, -3.10281634e-01, -7.46394992e-01,\n",
       "        1.22386515e+00,  3.28293085e-01,  8.60112906e-03, -8.73719007e-02,\n",
       "        3.38761546e-02, -2.84525752e-02,  1.15668789e-01, -5.15195906e-01,\n",
       "        6.21646941e-02,  1.34712994e+00, -3.11061561e-01, -6.36744201e-01,\n",
       "        4.88179624e-01, -2.77166963e-01,  9.56570804e-02, -7.00146377e-01,\n",
       "       -6.79676414e-01,  6.56954050e-01, -3.85789335e-01,  1.07766628e+00,\n",
       "       -3.75308812e-01,  5.91052115e-01,  5.15008092e-01,  7.18320608e-02,\n",
       "        3.91758054e-01,  8.35668862e-01,  6.69405997e-01, -9.22933161e-01,\n",
       "       -2.60728151e-02,  1.06533504e+00, -3.17677557e-01,  1.06740564e-01,\n",
       "        3.81428212e-01,  2.59963870e-01,  4.12428796e-01, -3.05755973e-01,\n",
       "       -8.05590689e-01,  2.35599339e-01, -7.52540529e-01,  7.40389764e-01,\n",
       "       -4.68587816e-01,  5.08082569e-01,  1.80151165e-02, -4.99686658e-01,\n",
       "       -2.20723182e-01, -1.23598658e-01, -1.42091960e-01,  6.10768378e-01,\n",
       "       -9.57292765e-02,  1.00547396e-01, -3.45608324e-01,  2.30967134e-01,\n",
       "        4.19537649e-02, -1.56597853e-01, -1.25035465e-01,  2.26615429e-01,\n",
       "       -1.57860994e-01, -3.28355491e-01,  2.44609922e-01,  3.73057127e-02,\n",
       "       -6.09410644e-01,  9.04664934e-01,  1.15208015e-01, -3.01780224e-01,\n",
       "       -5.91585398e-01, -3.57525349e-01, -6.67454123e-01, -1.20341390e-01,\n",
       "       -1.06094968e+00,  4.21011716e-01,  1.23171628e-01, -2.13571146e-01,\n",
       "       -1.83321565e-01,  3.59558403e-01,  1.87468112e-01, -1.70829445e-02,\n",
       "        1.14374745e+00, -1.18021727e-01, -7.97017157e-01,  7.39715338e-01,\n",
       "       -5.67673922e-01, -7.39265144e-01,  1.13740802e+00,  4.12392139e-01,\n",
       "        4.10867602e-01, -3.34599197e-01,  5.71265817e-01, -1.61144257e-01,\n",
       "        7.82139376e-02, -3.81260186e-01,  1.29184395e-01, -4.75922704e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"President\").vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"President coal\")\n",
    "doc2 = nlp(\"Obama stands by EPA about pollution\")\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
